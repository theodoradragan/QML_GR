{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0eb31ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://qiskit.org/documentation/tutorials/circuits/1_getting_started_with_qiskit.html\n",
    "# https://qiskit.org/documentation/machine-learning/tutorials/03_quantum_kernel.html\n",
    "# https://github.com/marcinjastrzebski8/QuantumKernelEstimation  (useful as a small guide)\n",
    "# https://xavierbourretsicotte.github.io/SVM_implementation.html\n",
    "# https://courses.csail.mit.edu/6.867/wiki/images/a/a7/Qp-cvxopt.pdf  ===> how to use cvxopt\n",
    "\n",
    "# TODO : see if one can improve accuracy\n",
    "# TODO : graphics to draw the separation hyperplane and see if it has the margins promised in the paper\n",
    "from qiskit import QuantumRegister, ClassicalRegister, QuantumCircuit, execute, BasicAer, transpile, Aer, IBMQ\n",
    "from qiskit.circuit import ParameterVector\n",
    "from qiskit.circuit.library import ZZFeatureMap, PauliFeatureMap\n",
    "from qiskit.utils import QuantumInstance, algorithm_globals\n",
    "from qiskit_machine_learning.kernels import QuantumKernel\n",
    "from cvxopt import matrix, solvers\n",
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pandas import DataFrame, read_csv\n",
    "import os\n",
    "\n",
    "seed = 12345\n",
    "algorithm_globals.random_seed = seed\n",
    "plt.rcParams[\"figure.figsize\"] = (10,6)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0f342e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAFoCAYAAAASDFxZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAeLklEQVR4nO3df4xd5X3n8fenDATXP5YQZqmSCNxkAUVusNOOWmldd1HayKEVCwpRlUAgbLRhBWKzandRqRoalkalSdTdNltKipZNgKS0UWp+dLMtKBtYxTTZZmjW0GmL29KQBtoyIdh4jIsx/e4f905yczP2jGeOZ547fr+ko5n7PM995nuea19/fM49Z1JVSJIkqQ3fs9IFSJIk6dsMZ5IkSQ0xnEmSJDXEcCZJktQQw5kkSVJDDGeSJEkNGVvpArp02mmn1caNG1e6DEmSpHk98sgj36iq8eH2VRXONm7cyOTk5EqXIUmSNK8kT87V7mlNSZKkhhjOJEmSGmI4kyRJaojhTJIkqSGGM0mSpIYYziRJkhpiOJMkSWqI4UySJKkhhjNJkqSGdPobApJcA1wBvBG4q6quOMLYnwF+Dvhe4DPAVVX1Yr9vI/Bx4EeArwHXVNXnuqxVOlr3fOUpPnL/4zy95wCvPmUN124/h4ve9JqR/DnLtS9anC5en1F6jVdTrQvZl67GHOt9WU7Lta5LrWO5pKq6myx5G/BPwHZgzeHCWZLtwB3Am4GngbuBL1XVdf3+LwJfBH4B+EngNuCsqpo+0s+fmJgof32TjoV7vvIUP7/jMQ689PK32taceAI3ve2Nnf7FXY6fs1z7osXp4vUZpdd4NdW6kH3pasyx3pfltFzrutQ6joUkj1TVxHB7p6c1q2pHVd0DPDvP0HcDt1XVVFU9B/wSvSNuJDkb+EHgA1V1oKp+D3gMuLjLWqWj8ZH7H/+Ov7AAB156mY/c//jI/Zzl2hctThevzyi9xqup1oXsS1djlqqldV+udV1qHctppT5ztgnYNfB4F3B6klf1+56oqn1D/ZvmmijJlUkmk0xOTx/xwJq0aE/vOXBU7S3/nOXaFy1OF6/PKL3Gq6nWhexLV2OWqqV1X651XWody2mlwtk6YO/A49nv18/RN9u/fq6JqurWqpqoqonx8fHOC5UAXn3KmqNqb/nnLNe+aHG6eH1G6TVeTbUuZF+6GrNULa37cq3rUutYTisVzmaADQOPZ7/fN0ffbP8+pBVy7fZzWHPiCd/RtubEE7h2+zkj93OWa1+0OF28PqP0Gq+mWheyL12NWaqW1n251nWpdSynTq/WPApTwGbg0/3Hm4F/qKpnk0wBr0uyfuDU5mbgt1egTgngWx8GPdZX8SzHz1mufdHidPH6jNJrvJpqXci+dDXmWO/LclqudV1qHcup66s1x+gFvg8ArwXeCxyqqkND494KfIJvX625A/jjgas1vwTsBN4PnE/vthperSlJklaNZblak16YOgBcB7yr//37k5yRZCbJGQBV9YfAh4EH6d3H7El6gW7WO4AJ4DngV4C3zxfMJEmSVoNOj5ytNI+cSZKkUbFcR84kSZK0BIYzSZKkhhjOJEmSGmI4kyRJaojhTJIkqSGGM0mSpIYYziRJkhpiOJMkSWqI4UySJKkhhjNJkqSGGM4kSZIaYjiTJElqiOFMkiSpIYYzSZKkhhjOJEmSGmI4kyRJaojhTJIkqSGGM0mSpIYYziRJkhpiOJMkSWqI4UySJKkhhjNJkqSGGM4kSZIaYjiTJElqiOFMkiSpIYYzSZKkhhjOJEmSGtJpOEtyapK7k+xP8mSSSw4z7g+SzAxsB5M8NtD/1SQHBvof6LJOSZKkVo11PN/NwEHgdGAL8Nkku6pqanBQVZ0/+DjJQ8Dnh+a6oKo+13F9kiRJTevsyFmStcDFwPVVNVNVO4H7gMvmed5GYBtwR1e1SJIkjaouT2ueDRyqqt0DbbuATfM873LgC1X11aH2TyWZTvJAks0d1ilJktSsLsPZOuD5oba9wPp5nnc58ImhtkuBjcCZwIPA/UlOmevJSa5MMplkcnp6+ihLliRJakuX4WwG2DDUtgHYd7gnJPlR4PuAzwy2V9XDVXWgql6oqpuAPfROfX6Xqrq1qiaqamJ8fHwp9UuSJK24LsPZbmAsyVkDbZuBqcOMB3g3sKOqZuaZu4AssT5JkqTmdRbOqmo/sAO4McnaJFuBC4E75xqfZA3w0wyd0kxyRpKtSU5KcnKSa4HTgIe7qlWSJKlVXd+E9mpgDfAMcBdwVVVNJdmWZPjo2EX0Tlc+ONS+HrgFeA54CngrcH5VPdtxrZIkSc1JVa10DZ2ZmJioycnJlS5DkiRpXkkeqaqJ4XZ/fZMkSVJDDGeSJEkNMZxJkiQ1xHAmSZLUEMOZJElSQwxnkiRJDTGcSZIkNcRwJkmS1BDDmSRJUkMMZ5IkSQ0xnEmSJDXEcCZJktQQw5kkSVJDDGeSJEkNMZxJkiQ1xHAmSZLUEMOZJElSQwxnkiRJDTGcSZIkNcRwJkmS1BDDmSRJUkMMZ5IkSQ0xnEmSJDXEcCZJktQQw5kkSVJDDGeSJEkNMZxJkiQ1pNNwluTUJHcn2Z/kySSXHGbcDUleSjIzsL1uoH9LkkeSvND/uqXLOiVJklrV9ZGzm4GDwOnApcAtSTYdZuzvVtW6ge0JgCQnAfcCnwReCdwO3NtvlyRJWtU6C2dJ1gIXA9dX1UxV7QTuAy47yqnOA8aAX6uqF6vqo0CAN3dVqyRJUqu6PHJ2NnCoqnYPtO0CDnfk7IIk30wyleSqgfZNwKNVVQNtjx5hHkmSpFWjy3C2Dnh+qG0vsH6OsZ8G3gCMA+8FfjHJOwfm2bvAeUhyZZLJJJPT09OLrV2SJKkJXYazGWDDUNsGYN/wwKr6s6p6uqperqo/An4dePvRztOf69aqmqiqifHx8SXtgCRJ0krrMpztBsaSnDXQthmYWsBzi97nyuiPPzdJBvrPXeA8kiRJI62zcFZV+4EdwI1J1ibZClwI3Dk8NsmFSV6Znh8G3kfvCk2Ah4CXgfcleUWSa/rtn++qVkmSpFZ1fSuNq4E1wDPAXcBVVTWVZFuSmYFx7wD+it6pyjuAD1XV7QBVdRC4CLgc2AO8B7io3y5JkrSqjXU5WVV9k16wGm7/Ar0P+s8+fufwmKHxXwF+qMvaJEmSRoG/vkmSJKkhhjNJkqSGGM4kSZIaYjiTJElqiOFMkiSpIYYzSZKkhhjOJEmSGmI4kyRJaojhTJIkqSGGM0mSpIYYziRJkhpiOJMkSWqI4UySJKkhhjNJkqSGGM4kSZIaYjiTJElqiOFMkiSpIYYzSZKkhhjOJEmSGmI4kyRJaojhTJIkqSGGM0mSpIYYziRJkhpiOJMkSWqI4UySJKkhhjNJkqSGGM4kSZIa0mk4S3JqkruT7E/yZJJLDjPu2iR/mmRfkr9Jcu1Q/1eTHEgy098e6LJOSZKkVo11PN/NwEHgdGAL8Nkku6pqamhcgMuBR4HXAw8k+duq+p2BMRdU1ec6rk+SJKlpnR05S7IWuBi4vqpmqmoncB9w2fDYqvpwVf1JVR2qqseBe4GtXdUiSZI0qro8rXk2cKiqdg+07QI2HelJSQJsA4aPrn0qyXSSB5Js7rBOSZKkZnUZztYBzw+17QXWz/O8G/p1fHyg7VJgI3Am8CBwf5JT5npykiuTTCaZnJ6ePvqqJUmSGtJlOJsBNgy1bQD2He4JSa6h99mzn6qqF2fbq+rhqjpQVS9U1U3AHnpH175LVd1aVRNVNTE+Pr7UfZAkSVpRXYaz3cBYkrMG2jbz3acrAUjyHuA64Mer6uvzzF30LiKQJEla1ToLZ1W1H9gB3JhkbZKtwIXAncNjk1wK/DLwlqp6YqjvjCRbk5yU5OT+bTZOAx7uqlZJkqRWdX0T2quBNcAzwF3AVVU1lWRbkpmBcR8EXgV8eeBeZh/r960HbgGeA54C3gqcX1XPdlyrJElSczq9z1lVfRO4aI72L9C7YGD28fcfYY4p4Nwu65IkSRoV/vomSZKkhhjOJEmSGmI4kyRJaojhTJIkqSGGM0mSpIYYziRJkhpiOJMkSWqI4UySJKkhhjNJkqSGGM4kSZIaYjiTJElqiOFMkiSpIYYzSZKkhhjOJEmSGmI4kyRJaojhTJIkqSGGM0mSpIYYziRJkhpiOJMkSWqI4UySJKkhhjNJkqSGGM4kSZIaYjiTJElqiOFMkiSpIYYzSZKkhhjOJEmSGmI4kyRJakin4SzJqUnuTrI/yZNJLjnMuCT5UJJn+9uHkmSgf0uSR5K80P+6pcs6JUmSWtX1kbObgYPA6cClwC1JNs0x7krgImAzcC5wAfDvAJKcBNwLfBJ4JXA7cG+/XZIkaVXrLJwlWQtcDFxfVTNVtRO4D7hsjuHvBn61qr5eVU8Bvwpc0e87DxgDfq2qXqyqjwIB3txVrZIkSa3q8sjZ2cChqto90LYLmOvI2aZ+31zjNgGPVlUN9D96mHkkSZJWlS7D2Trg+aG2vcD6w4zdOzRuXf9zZ8N9R5qHJFcmmUwyOT09vajCJUmSWtFlOJsBNgy1bQD2LWDsBmCmf7TsaOahqm6tqomqmhgfH19U4ZIkSa3oMpztBsaSnDXQthmYmmPsVL9vrnFTwLmDV2/Su2hgrnkkSZJWlc7CWVXtB3YANyZZm2QrcCFw5xzD7wB+Nslrkrwa+I/AJ/p9DwEvA+9L8ook1/TbP99VrZIkSa3q+lYaVwNrgGeAu4CrqmoqybYkMwPjfgv4feAx4E+Bz/bbqKqD9G6zcTmwB3gPcFG/XZIkaVXLd14UOdomJiZqcnJypcuQJEmaV5JHqmpiuN1f3yRJktQQw5kkSVJDDGeSJEkNMZxJkiQ1xHAmSZLUEMOZJElSQwxnkiRJDTGcSZIkNcRwJkmS1BDDmSRJUkMMZ5IkSQ0xnEmSJDXEcCZJktQQw5kkSVJDDGeSJEkNMZxJkiQ1xHAmSZLUEMOZJElSQwxnkiRJDTGcSZIkNcRwJkmS1BDDmSRJUkMMZ5IkSQ0xnEmSJDXEcCZJktQQw5kkSVJDDGeSJEkN6SScJTk1yd1J9id5MsklRxh7bZI/TbIvyd8kuXao/6tJDiSZ6W8PdFGjJEnSKBjraJ6bgYPA6cAW4LNJdlXV1BxjA1wOPAq8Hnggyd9W1e8MjLmgqj7XUW2SJEkjY8lHzpKsBS4Grq+qmaraCdwHXDbX+Kr6cFX9SVUdqqrHgXuBrUutQ5IkaTXo4rTm2cChqto90LYL2DTfE5ME2AYMH2H7VJLpJA8k2dxBjZIkSSOhi3C2Dnh+qG0vsH4Bz72hX8PHB9ouBTYCZwIPAvcnOeVwEyS5Mslkksnp6emFVy1JktSgecNZkoeS1GG2ncAMsGHoaRuAffPMew29z579VFW9ONteVQ9X1YGqeqGqbgL20Du6NqequrWqJqpqYnx8fL7dkSRJatq8FwRU1XlH6u9/5mwsyVlV9Zf95s1896nKwee8B7gO+LGq+vp8JdC7iECSJGnVW/JpzaraD+wAbkyyNslW4ELgzrnGJ7kU+GXgLVX1xFDfGUm2Jjkpycn922ycBjy81DolSZJGQVc3ob0aWAM8A9wFXDV7G40k25LMDIz9IPAq4MsD9zL7WL9vPXAL8BzwFPBW4PyqerajOiVJkprWyX3OquqbwEWH6fsCvYsGZh9//xHmmQLO7aImSZKkUeSvb5IkSWqI4UySJKkhhjNJkqSGGM4kSZIaYjiTJElqiOFMkiSpIYYzSZKkhhjOJEmSGmI4kyRJaojhTJIkqSGGM0mSpIYYziRJkhpiOJMkSWqI4UySJKkhhjNJkqSGGM4kSZIaYjiTJElqiOFMkiSpIYYzSZKkhhjOJEmSGmI4kyRJaojhTJIkqSGGM0mSpIYYziRJkhpiOJMkSWqI4UySJKkhhjNJkqSGdBbOkpya5O4k+5M8meSSI4y9IclLSWYGttcN9G9J8kiSF/pft3RVpyRJUsu6PHJ2M3AQOB24FLglyaYjjP/dqlo3sD0BkOQk4F7gk8ArgduBe/vtkiRJq1on4SzJWuBi4PqqmqmqncB9wGWLmO48YAz4tap6sao+CgR4cxe1SpIktayrI2dnA4eqavdA2y7gSEfOLkjyzSRTSa4aaN8EPFpVNdD26DxzSZIkrQpdhbN1wPNDbXuB9YcZ/2ngDcA48F7gF5O8c2CuvQudK8mVSSaTTE5PTy+mdkmSpGYsKJwleShJHWbbCcwAG4aetgHYN9d8VfVnVfV0Vb1cVX8E/Drw9n730c51a1VNVNXE+Pj4QnZHkiSpWQsKZ1V1XlXlMNuPAruBsSRnDTxtMzC1wDqK3ufK6D/n3CQZ6D/3KOaSJEkaWZ2c1qyq/cAO4MYka5NsBS4E7pxrfJILk7wyPT8MvI/eFZoADwEvA+9L8ook1/TbP99FrZIkSS3r8lYaVwNrgGeAu4CrqmoKIMm2JDMDY98B/BW9U5V3AB+qqtsBquogcBFwObAHeA9wUb9dkiRpVRvraqKq+ia9UDVX3xfofdB/9vE75xo30P8V4Ie6qk2SJGlU+OubJEmSGmI4kyRJaojhTJIkqSGGM0mSpIYYziRJkhpiOJMkSWqI4UySJKkhhjNJkqSGGM4kSZIaYjiTJElqiOFMkiSpIYYzSZKkhhjOJEmSGmI4kyRJaojhTJIkqSGGM0mSpIYYziRJkhpiOJMkSWqI4UySJKkhhjNJkqSGGM4kSZIaYjiTJElqiOFMkiSpIYYzSZKkhhjOJEmSGmI4kyRJaojhTJIkqSGdhLMkpya5O8n+JE8mueQIY/8gyczAdjDJYwP9X01yYKD/gS5qlCRJGgVjHc1zM3AQOB3YAnw2ya6qmhoeWFXnDz5O8hDw+aFhF1TV5zqqTZIkaWQs+chZkrXAxcD1VTVTVTuB+4DLFvDcjcA24I6l1iFJkrQadHFa82zgUFXtHmjbBWxawHMvB75QVV8dav9UkukkDyTZ3EGNkiRJI6GLcLYOeH6obS+wfgHPvRz4xFDbpcBG4EzgQeD+JKccboIkVyaZTDI5PT29wJIlSZLaNG84S/JQkjrMthOYATYMPW0DsG+eeX8U+D7gM4PtVfVwVR2oqheq6iZgD71Tn3OqqluraqKqJsbHx+fbHUmSpKbNe0FAVZ13pP7+Z87GkpxVVX/Zb94MfNfFAEPeDeyoqpn5SgAyX52SJEmrwZJPa1bVfmAHcGOStUm2AhcCdx7uOUnWAD/N0CnNJGck2ZrkpCQnJ7kWOA14eKl1SpIkjYKubkJ7NbAGeAa4C7hq9jYaSbYlGT46dhG905UPDrWvB24BngOeAt4KnF9Vz3ZUpyRJUtNSVStdQ2cmJiZqcnJypcuQJEmaV5JHqmpiuN1f3yRJktQQw5kkSVJDDGeSJEkNMZxJkiQ1xHAmSZLUEMOZJElSQwxnkiRJDTGcSZIkNcRwJkmS1BDDmSRJUkMMZ5IkSQ0xnEmSJDXEcCZJktQQw5kkSVJDDGeSJEkNMZxJkiQ1xHAmSZLUEMOZJElSQwxnkiRJDTGcSZIkNcRwJkmS1BDDmSRJUkMMZ5IkSQ0xnEmSJDXEcCZJktQQw5kkSVJDDGeSJEkNMZxJkiQ1ZKyLSZJcA1wBvBG4q6qumGf8zwA/B3wv8Bngqqp6sd+3Efg48CPA14BrqupzXdS5FPd85Sk+cv/jPL3nAK8+ZQ3Xbj+Hi970ms7nmG9MF3V0Zblq6WJNRmld53O81TpK+3s8Wo7Xp5X3Gmm5pKqWPknyNuCfgO3AmiOFsyTbgTuANwNPA3cDX6qq6/r9XwS+CPwC8JPAbcBZVTU9Xx0TExM1OTm5tJ2Zwz1feYqf3/EYB156+Vtta048gZve9sYF/8VdyBzzjemijq4sVy1drMkoret8jrdaR2l/j0fL8fq08l4jHQtJHqmqieH2Tk5rVtWOqroHeHYBw98N3FZVU1X1HPBL9I66keRs4AeBD1TVgar6PeAx4OIu6lysj9z/+Hf8hQU48NLLfOT+xzudY74xXdTRleWqpYs1GaV1nc/xVuso7e/xaDlen1bea6TltBKfOdsE7Bp4vAs4Pcmr+n1PVNW+of5Nh5ssyZVJJpNMTk/Pe3BtUZ7ec+Co2hc7x3xjuqijK8tVSxdrMkrrOp/jrdZR2t/j0XK8Pq2810jLaSXC2Tpg78Dj2e/Xz9E327/+cJNV1a1VNVFVE+Pj450WOuvVp6w5qvbFzjHfmC7q6Mpy1dLFmozSus7neKt1lPb3eLQcr08r7zXScpo3nCV5KEkdZtu5iJ85A2wYeDz7/b45+mb797GCrt1+DmtOPOE72taceALXbj+n0znmG9NFHV1Zrlq6WJNRWtf5HG+1jtL+Ho+W4/Vp5b1GWk7zXq1ZVed1/DOngM3Ap/uPNwP/UFXPJpkCXpdk/cCpzc3Ab3dcw1GZ/TDoUq7iWcgc843poo6uLFctXazJKK3rfI63Wkdpf49Hy/H6tPJeIy2nrq7WHKMX9D4AvBZ4L3Coqg7NMfatwCf49tWaO4A/Hrha80vATuD9wPn0bquxoldrSpIkde2YXq1JL0gdAK4D3tX//v39H3xGkpkkZwBU1R8CHwYepHcfsyfphbpZ7wAmgOeAXwHevpBgJkmStBp0cuSsFR45kyRJo+JYHzmTJElSBwxnkiRJDTGcSZIkNcRwJkmS1BDDmSRJUkMMZ5IkSQ0xnEmSJDXEcCZJktSQVXUT2iTT9H7jwGKdBnyjo3L0ba7rseG6Hhuu67Hhuh4bruuxsVzremZVjQ83rqpwtlRJJue6U6+WxnU9NlzXY8N1PTZc12PDdT02VnpdPa0pSZLUEMOZJElSQwxn3+nWlS5glXJdjw3X9dhwXY8N1/XYcF2PjRVdVz9zJkmS1BCPnEmSJDXEcCZJktQQwxmQ5NQkdyfZn+TJJJesdE2jKMk1SSaTvJjkE0N9P57kL5K8kOTBJGeuUJkjJ8krktzW/7O5L8n/S3L+QL9ru0hJPpnk75I8n2R3kn870Oe6LkGSs5L8Y5JPDrRd0v9zvD/JPUlOXckaR02Sh/prOtPfHh/oc22XIMk7kvx5f/3+Osm2fvuKvA8YznpuBg4CpwOXArck2bSyJY2kp4EPAv9jsDHJacAO4HrgVGAS+N1lr250jQF/C/wr4J8B7wc+nWSja7tkNwEbq2oD8K+BDyb5Ide1EzcDX5590H9P/S3gMnrvtS8Av7kypY20a6pqXX87B1zbpUryFuBDwL8B1gM/Bjyxku8Dx/0FAUnWAs8BP1BVu/ttdwJPVdV1K1rciEryQeC1VXVF//GVwBVV9S/7j9fSu/Pym6rqL1as0BGW5FHgPwOvwrXtRJJzgIeA/wCcguu6aEneAbwN+DPgX1TVu5L8Mr0gfEl/zOuBPwdeVVX7Vq7a0ZHkIeCTVfXfh9pd2yVI8kfAbVV121D7iv3b5ZEzOBs4NBvM+nYBHjnrziZ6awpAVe0H/hrXeFGSnE7vz+0Uru2SJfnNJC8AfwH8HfC/cF0XLckG4EbgZ4e6htf0r+mdsTh7+apbFW5K8o0kDyc5r9/m2i5SkhOACWA8yV8l+XqS30iyhhV8HzCcwTrg+aG2vfQObaob6+it6SDXeBGSnAh8Cri9/z8313aJqupqeuu1jd4pjBdxXZfil+gdhfj6ULtrunQ/B7wOeA29+3D9fv8omWu7eKcDJwJvp/cesAV4E72Pj6zYuhrOYAbYMNS2AfBQcHdc4w4k+R7gTnr/I76m3+zadqCqXq6qncBrgatwXRclyRbgJ4D/Oke3a7pEVfV/q2pfVb1YVbcDDwM/iWu7FAf6X/9bVf1dVX0D+C+s8LoazmA3MJbkrIG2zfROGakbU/TWFPjWefvX4xovWJIAt9H7X97FVfVSv8u17dYY314/1/XonQdsBL6W5O+B/wRcnORP+O41fR3wCnrvwVqcAoJru2hV9RzwdXpr+a3m/tcVex847sNZ/xzyDuDGJGuTbAUupHeEQkchyViSk4ETgBOSnJxkDLgb+IEkF/f7fxF41A9WH5VbgDcAF1TVgYF213aRkvzz/uXz65KckGQ78E7gf+O6Ltat9P7x2tLfPgZ8FthO73T8BUm29f+RuxHY4QfWFybJKUm2z76vJrmU3lWFf4hru1QfB/59/z3hlcDPAP+TlXwfqKrjfqN3iew9wH7ga8AlK13TKG7ADfT+xzG43dDv+wl6H7g+QO+KuI0rXe+obMCZ/bX8R3qH2We3S13bJa3rOPB/gD30Pnf6GPDegX7XdelrfAO9qwtnH1/Sf4/dD9wLnLrSNY7K1v/z+mV6p9T2AF8C3uLadrK2J9K79cge4O+BjwIn9/tW5H3guL+VhiRJUkuO+9OakiRJLTGcSZIkNcRwJkmS1BDDmSRJUkMMZ5IkSQ0xnEmSJDXEcCZJktQQw5kkSVJDDGeSJEkN+f+yMEcQFeZd4QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating a dataset\n",
    "\n",
    "num_features = 6\n",
    "#df = read_csv(\"dataset_p_173_g_5_s_40.csv\")\n",
    "df = read_csv(\"dataset_p_61_g_5_s_15.csv\")\n",
    "num_samples_train = int(0.75 * len(df))\n",
    "num_samples_test = len(df) - num_samples_train\n",
    "\n",
    "all_features = list(df['x'])\n",
    "all_features_bin = [[int(r) for r in (list(format(all_features[idx], '06b')))] for idx in range(len(df))]\n",
    "#print(all_features_bin)\n",
    "\n",
    "features_train = all_features_bin[:num_samples_train]\n",
    "features_test = all_features_bin[num_samples_train:]\n",
    "#print(features_train)\n",
    "#print(features_test)\n",
    "\n",
    "labels = np.array(df['y'])\n",
    "labels_train = labels[:num_samples_train]\n",
    "labels_test = labels[num_samples_train:]\n",
    "#print(labels_train)\n",
    "#print(labels_test)\n",
    "\n",
    "plt.plot(all_features, labels, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a537512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X', 'ZY', 'XZY']\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.0989e-02 -3.2945e-02  2e-02  0e+00  1e+00\n",
      " 1: -1.0989e-02 -1.1209e-02  2e-04  1e-18  1e-02\n",
      " 2: -1.0989e-02 -1.0991e-02  2e-06  9e-19  1e-04\n",
      " 3: -1.0989e-02 -1.0989e-02  2e-08  8e-19  1e-06\n",
      " 4: -1.0989e-02 -1.0989e-02  2e-10  9e-19  1e-08\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.0891e-01 -3.2463e-01  2e-01  0e+00  1e+00\n",
      " 1: -1.0892e-01 -1.1110e-01  2e-03  8e-18  1e-02\n",
      " 2: -1.0892e-01 -1.0894e-01  2e-05  9e-18  1e-04\n",
      " 3: -1.0892e-01 -1.0892e-01  2e-07  7e-18  1e-06\n",
      " 4: -1.0892e-01 -1.0892e-01  2e-09  8e-18  1e-08\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -9.9459e-01 -2.8409e+00  2e+00  0e+00  1e+00\n",
      " 1: -1.0010e+00 -1.0234e+00  2e-02  7e-17  4e-02\n",
      " 2: -1.0016e+00 -1.0018e+00  2e-04  1e-16  3e-04\n",
      " 3: -1.0016e+00 -1.0016e+00  2e-06  6e-17  3e-06\n",
      " 4: -1.0016e+00 -1.0016e+00  2e-08  8e-17  3e-08\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.9936e+00 -1.3081e+01  8e+00  0e+00  1e+00\n",
      " 1: -5.5489e+00 -5.8827e+00  3e-01  4e-16  2e-01\n",
      " 2: -5.6709e+00 -5.6798e+00  9e-03  4e-16  1e-03\n",
      " 3: -5.6709e+00 -5.6710e+00  9e-05  6e-16  1e-05\n",
      " 4: -5.6709e+00 -5.6709e+00  9e-07  4e-16  1e-07\n",
      " 5: -5.6709e+00 -5.6709e+00  9e-09  4e-16  1e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -8.0835e+00 -2.0752e+01  1e+01  0e+00  2e+00\n",
      " 1: -1.0112e+01 -1.1250e+01  1e+00  7e-16  4e-01\n",
      " 2: -1.1008e+01 -1.1126e+01  1e-01  1e-15  3e-03\n",
      " 3: -1.1008e+01 -1.1009e+01  1e-03  1e-15  3e-05\n",
      " 4: -1.1008e+01 -1.1008e+01  1e-05  9e-16  3e-07\n",
      " 5: -1.1008e+01 -1.1008e+01  1e-07  7e-16  3e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -8.6044e+00 -2.2053e+01  1e+01  0e+00  2e+00\n",
      " 1: -1.1005e+01 -1.2372e+01  1e+00  8e-16  4e-01\n",
      " 2: -1.2211e+01 -1.2394e+01  2e-01  8e-16  4e-03\n",
      " 3: -1.2211e+01 -1.2213e+01  2e-03  9e-16  4e-05\n",
      " 4: -1.2211e+01 -1.2212e+01  2e-05  1e-15  4e-07\n",
      " 5: -1.2211e+01 -1.2211e+01  2e-07  9e-16  4e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -8.6600e+00 -2.2192e+01  1e+01  0e+00  2e+00\n",
      " 1: -1.1103e+01 -1.2497e+01  1e+00  6e-16  4e-01\n",
      " 2: -1.2348e+01 -1.2539e+01  2e-01  9e-16  4e-03\n",
      " 3: -1.2348e+01 -1.2350e+01  2e-03  9e-16  4e-05\n",
      " 4: -1.2348e+01 -1.2348e+01  2e-05  1e-15  4e-07\n",
      " 5: -1.2348e+01 -1.2348e+01  2e-07  1e-15  4e-09\n",
      "Optimal solution found.\n",
      "['Y', 'ZY', 'XZY']\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.0988e-02 -3.2943e-02  2e-02  0e+00  1e+00\n",
      " 1: -1.0988e-02 -1.1208e-02  2e-04  1e-18  1e-02\n",
      " 2: -1.0988e-02 -1.0990e-02  2e-06  9e-19  1e-04\n",
      " 3: -1.0988e-02 -1.0988e-02  2e-08  1e-18  1e-06\n",
      " 4: -1.0988e-02 -1.0988e-02  2e-10  1e-18  1e-08\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.0882e-01 -3.2435e-01  2e-01  0e+00  1e+00\n",
      " 1: -1.0883e-01 -1.1100e-01  2e-03  8e-18  1e-02\n",
      " 2: -1.0883e-01 -1.0885e-01  2e-05  9e-18  1e-04\n",
      " 3: -1.0883e-01 -1.0883e-01  2e-07  1e-17  1e-06\n",
      " 4: -1.0883e-01 -1.0883e-01  2e-09  8e-18  1e-08\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -9.8659e-01 -2.8132e+00  2e+00  0e+00  1e+00\n",
      " 1: -9.9285e-01 -1.0135e+00  2e-02  1e-16  3e-02\n",
      " 2: -9.9341e-01 -9.9362e-01  2e-04  9e-17  3e-04\n",
      " 3: -9.9341e-01 -9.9341e-01  2e-06  6e-17  3e-06\n",
      " 4: -9.9341e-01 -9.9341e-01  2e-08  7e-17  3e-08\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.7595e+00 -1.2190e+01  7e+00  0e+00  1e+00\n",
      " 1: -5.2422e+00 -5.4431e+00  2e-01  4e-16  2e-01\n",
      " 2: -5.3326e+00 -5.3366e+00  4e-03  3e-16  1e-04\n",
      " 3: -5.3326e+00 -5.3326e+00  4e-05  4e-16  1e-06\n",
      " 4: -5.3326e+00 -5.3326e+00  4e-07  4e-16  1e-08\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -7.4478e+00 -1.8336e+01  1e+01  0e+00  2e+00\n",
      " 1: -9.0396e+00 -9.6024e+00  6e-01  5e-16  3e-01\n",
      " 2: -9.5375e+00 -9.5776e+00  4e-02  8e-16  1e-16\n",
      " 3: -9.5375e+00 -9.5379e+00  4e-04  8e-16  1e-16\n",
      " 4: -9.5375e+00 -9.5375e+00  4e-06  8e-16  1e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -7.8819e+00 -1.9311e+01  1e+01  0e+00  2e+00\n",
      " 1: -9.7323e+00 -1.0386e+01  7e-01  7e-16  3e-01\n",
      " 2: -1.0363e+01 -1.0419e+01  6e-02  6e-16  2e-16\n",
      " 3: -1.0363e+01 -1.0363e+01  6e-04  7e-16  2e-16\n",
      " 4: -1.0363e+01 -1.0363e+01  6e-06  1e-15  1e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -7.9279e+00 -1.9414e+01  1e+01  0e+00  2e+00\n",
      " 1: -9.8072e+00 -1.0471e+01  7e-01  7e-16  3e-01\n",
      " 2: -1.0453e+01 -1.0512e+01  6e-02  8e-16  1e-16\n",
      " 3: -1.0453e+01 -1.0454e+01  6e-04  7e-16  2e-16\n",
      " 4: -1.0453e+01 -1.0453e+01  6e-06  9e-16  2e-16\n",
      "Optimal solution found.\n",
      "['Z', 'ZY', 'XZY']\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.0989e-02 -3.2944e-02  2e-02  0e+00  1e+00\n",
      " 1: -1.0989e-02 -1.1208e-02  2e-04  1e-18  1e-02\n",
      " 2: -1.0989e-02 -1.0991e-02  2e-06  9e-19  1e-04\n",
      " 3: -1.0989e-02 -1.0989e-02  2e-08  9e-19  1e-06\n",
      " 4: -1.0989e-02 -1.0989e-02  2e-10  8e-19  1e-08\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.0886e-01 -3.2446e-01  2e-01  0e+00  1e+00\n",
      " 1: -1.0887e-01 -1.1104e-01  2e-03  1e-17  1e-02\n",
      " 2: -1.0887e-01 -1.0889e-01  2e-05  8e-18  1e-04\n",
      " 3: -1.0887e-01 -1.0887e-01  2e-07  1e-17  1e-06\n",
      " 4: -1.0887e-01 -1.0887e-01  2e-09  7e-18  1e-08\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -9.8964e-01 -2.8219e+00  2e+00  0e+00  1e+00\n",
      " 1: -9.9596e-01 -1.0168e+00  2e-02  9e-17  3e-02\n",
      " 2: -9.9652e-01 -9.9674e-01  2e-04  7e-17  3e-04\n",
      " 3: -9.9652e-01 -9.9653e-01  2e-06  7e-17  3e-06\n",
      " 4: -9.9652e-01 -9.9653e-01  2e-08  8e-17  3e-08\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.8296e+00 -1.2379e+01  8e+00  0e+00  1e+00\n",
      " 1: -5.3313e+00 -5.5490e+00  2e-01  3e-16  2e-01\n",
      " 2: -5.4274e+00 -5.4317e+00  4e-03  5e-16  1e-16\n",
      " 3: -5.4274e+00 -5.4275e+00  4e-05  4e-16  1e-16\n",
      " 4: -5.4274e+00 -5.4274e+00  4e-07  3e-16  2e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -7.6163e+00 -1.8789e+01  1e+01  0e+00  2e+00\n",
      " 1: -9.3036e+00 -9.9498e+00  6e-01  5e-16  3e-01\n",
      " 2: -9.8582e+00 -9.9074e+00  5e-02  5e-16  2e-16\n",
      " 3: -9.8583e+00 -9.8587e+00  5e-04  7e-16  1e-16\n",
      " 4: -9.8583e+00 -9.8583e+00  5e-06  8e-16  1e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -8.0700e+00 -1.9817e+01  1e+01  0e+00  2e+00\n",
      " 1: -1.0037e+01 -1.0796e+01  8e-01  7e-16  3e-01\n",
      " 2: -1.0745e+01 -1.0816e+01  7e-02  8e-16  1e-16\n",
      " 3: -1.0746e+01 -1.0746e+01  7e-04  9e-16  1e-16\n",
      " 4: -1.0746e+01 -1.0746e+01  7e-06  9e-16  1e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -8.1182e+00 -1.9926e+01  1e+01  0e+00  2e+00\n",
      " 1: -1.0117e+01 -1.0888e+01  8e-01  6e-16  3e-01\n",
      " 2: -1.0843e+01 -1.0916e+01  7e-02  9e-16  1e-16\n",
      " 3: -1.0843e+01 -1.0844e+01  7e-04  7e-16  2e-16\n",
      " 4: -1.0843e+01 -1.0843e+01  7e-06  1e-15  1e-16\n",
      "Optimal solution found.\n"
     ]
    }
   ],
   "source": [
    "### Custom Feature Map\n",
    "\n",
    "# for now, we have as many qubits as features\n",
    "num_qubits = num_features\n",
    "      \n",
    "# creating the feature map and extracting the kernel matrix\n",
    "backend = QuantumInstance(Aer.get_backend(\"qasm_simulator\"), shots=1024, seed_simulator=seed, seed_transpiler=seed)\n",
    "\n",
    "for gate1 in ['X','Y', 'Z']:\n",
    "    #for gate2 in ['X', 'Y', 'Z']:\n",
    "    #    for gate3 in ['X', 'Y', 'Z']:\n",
    "\n",
    "    paulis = [gate1, 'ZY', 'XZY']#, gate2+gate3]\n",
    "    print(paulis)\n",
    "\n",
    "    paulis_string = \"_\".join(paulis)\n",
    "    foldername = \"./all_results_for_DLP_ds_\" + paulis_string + \"/\"\n",
    "    os.mkdir(foldername)\n",
    "\n",
    "    fm = PauliFeatureMap(num_qubits, reps=1, paulis=paulis)\n",
    "    qk = QuantumKernel(feature_map=fm, quantum_instance=backend)\n",
    "    K = qk.evaluate(features_train)\n",
    "\n",
    "    numerical_results_filename = foldername + 'accuracy_results.txt'\n",
    "\n",
    "    lambda_best_acc = -1\n",
    "    best_acc = -1\n",
    "    # Computing the alphas of the SVM algorithm\n",
    "    for lambda_svm in [0.001, 0.01, 0.1, 1, 10, 100, 1000]:\n",
    "        Q = np.zeros((num_samples_train, num_samples_train))\n",
    "        for i in range(num_samples_train):\n",
    "            for j in range(num_samples_train):\n",
    "                Q[i][j] = labels[i] * labels[j] * K[i][j]\n",
    "        Pm = np.eye(num_samples_train) / lambda_svm + Q\n",
    "\n",
    "        P = matrix(Pm, tc='d')\n",
    "        q = matrix(-np.ones(num_samples_train), tc='d')\n",
    "        G = matrix(-np.eye(num_samples_train), tc='d')\n",
    "        h = matrix(np.zeros(num_samples_train), tc='d')\n",
    "\n",
    "        sol = solvers.qp(P,q,G,h)\n",
    "        alpha = (np.array(sol['x']).T)[0]\n",
    "        good = 0\n",
    "        bad = 0\n",
    "        for test_idx in range(num_samples_test):\n",
    "            new_sum = 0\n",
    "\n",
    "            for train_idx in range(num_samples_train):\n",
    "                pair = np.zeros((2, num_features))\n",
    "                pair[0] = features_train[train_idx]\n",
    "                pair[1] = features_test[test_idx]\n",
    "                current_K = qk.evaluate(pair)\n",
    "                new_sum = new_sum + alpha[train_idx] * labels_train[train_idx] * current_K[0][1] # x_i vs x (test)\n",
    "\n",
    "            if int(new_sum/abs(new_sum)) == int(labels_test[test_idx]):\n",
    "                good = good + 1\n",
    "            #    print(\"Good for \" + str(test_idx))\n",
    "            else:\n",
    "                bad = bad + 1\n",
    "            #    print(\"Bad for \" + str(test_idx))\n",
    "\n",
    "            if round(good / (good + bad), 4) * 100 > best_acc:\n",
    "                best_acc = round(good / (good + bad), 4) * 100\n",
    "                lambda_best_acc = lambda_svm\n",
    "\n",
    "        with open(numerical_results_filename, 'a') as f:\n",
    "            print(\"Lambda is: \", lambda_svm, file=f)\n",
    "            print(\"Well classifed: \", good, file=f)\n",
    "            print(\"Bad classified: \", bad, file=f)\n",
    "            print(\"Accuracy: \", round(good / (good + bad), 4) * 100, file=f)\n",
    "            print('\\n################################\\n', file=f)\n",
    "\n",
    "    \"\"\"\n",
    "    # Plot for best lambda\n",
    "    lambda_svm = lambda_best_acc # we plot for the best lambda\n",
    "    Q = np.zeros((num_samples_train, num_samples_train))\n",
    "    for i in range(num_samples_train):\n",
    "        for j in range(num_samples_train):\n",
    "            Q[i][j] = labels[i] * labels[j] * K[i][j]\n",
    "    Pm = np.eye(num_samples_train) / lambda_svm + Q\n",
    "\n",
    "    P = matrix(Pm, tc='d')\n",
    "    q = matrix(-np.ones(num_samples_train), tc='d')\n",
    "    G = matrix(-np.eye(num_samples_train), tc='d')\n",
    "    h = matrix(np.zeros(num_samples_train), tc='d')\n",
    "\n",
    "    sol = solvers.qp(P,q,G,h)\n",
    "    alpha = (np.array(sol['x']).T)[0]\n",
    "    print(alpha[0:4])\n",
    "    good = 0\n",
    "    bad = 0\n",
    "\n",
    "    w_0 = 0\n",
    "    w_1 = 0\n",
    "    w_2 = 0\n",
    "    w_3 = 0\n",
    "\n",
    "    for test_idx in range(num_samples_test):\n",
    "        new_sum = 0\n",
    "\n",
    "        for train_idx in range(num_samples_train):\n",
    "            pair = np.zeros((2, num_features))\n",
    "            pair[0] = features_train[train_idx]\n",
    "            pair[1] = features_test[test_idx]\n",
    "            current_K = qk.evaluate(pair)\n",
    "            new_sum = new_sum + alpha[train_idx] * labels_train[train_idx] * current_K[0][1] # x_i vs x (test)\n",
    "            w_0 = w_0 + alpha[train_idx] * labels_train[train_idx] * features_train[train_idx][0]\n",
    "            w_1 = w_1 + alpha[train_idx] * labels_train[train_idx] * features_train[train_idx][1]\n",
    "            w_2 = w_2 + alpha[train_idx] * labels_train[train_idx] * features_train[train_idx][2]\n",
    "            w_3 = w_3 + alpha[train_idx] * labels_train[train_idx] * features_train[train_idx][3]\n",
    "\n",
    "    ##\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    for key, group in grouped:\n",
    "        group.plot(ax=ax, kind='scatter', x='feature 1', y='feature 2', label=key, color=colors[key])\n",
    "\n",
    "    x0_sample = np.linspace(-10.0, 10.0, num=1000)\n",
    "    x1_sample = -w_0 * x0_sample / w_1\n",
    "    ax.plot(x0_sample, x1_sample)\n",
    "\n",
    "    plt.savefig(foldername + 'pauli_fm_hyperplane_f1_f2.png')\n",
    "    plt.show()\n",
    "\n",
    "    ##\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    for key, group in grouped:\n",
    "        group.plot(ax=ax, kind='scatter', x='feature 2', y='feature 3', label=key, color=colors[key])\n",
    "\n",
    "    x0_sample = np.linspace(-10.0, 10.0, num=1000)\n",
    "    x1_sample = -w_1 * x0_sample / w_2\n",
    "    ax.plot(x0_sample, x1_sample)\n",
    "\n",
    "    plt.savefig(foldername + 'pauli_fm_hyperplane_f2_f3.png')\n",
    "    plt.show()\n",
    "\n",
    "    ##\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    for key, group in grouped:\n",
    "        group.plot(ax=ax, kind='scatter', x='feature 3', y='feature 4', label=key, color=colors[key])\n",
    "\n",
    "    x0_sample = np.linspace(-10.0, 10.0, num=1000)\n",
    "    x1_sample = -w_2 * x0_sample / w_3\n",
    "    ax.plot(x0_sample, x1_sample)\n",
    "\n",
    "    plt.savefig(foldername + 'pauli_fm_hyperplane_f3_f4.png')\n",
    "    plt.show()\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0dbeb1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "numerical_results_filename = foldername + 'accuracy_results.txt'\n",
    "\n",
    "lambda_best_acc = -1\n",
    "best_acc = -1\n",
    "# Computing the alphas of the SVM algorithm\n",
    "for lambda_svm in [0.001, 0.01, 0.1, 1, 10, 100, 1000]:\n",
    "    Q = np.zeros((num_samples_train, num_samples_train))\n",
    "    for i in range(num_samples_train):\n",
    "        for j in range(num_samples_train):\n",
    "            Q[i][j] = labels[i] * labels[j] * K[i][j]\n",
    "    Pm = np.eye(num_samples_train) / lambda_svm + Q\n",
    "\n",
    "    P = matrix(Pm, tc='d')\n",
    "    q = matrix(-np.ones(num_samples_train), tc='d')\n",
    "    G = matrix(-np.eye(num_samples_train), tc='d')\n",
    "    h = matrix(np.zeros(num_samples_train), tc='d')\n",
    "\n",
    "    sol = solvers.qp(P,q,G,h)\n",
    "    alpha = (np.array(sol['x']).T)[0]\n",
    "    good = 0\n",
    "    bad = 0\n",
    "    for test_idx in range(num_samples_test):\n",
    "        new_sum = 0\n",
    "\n",
    "        for train_idx in range(num_samples_train):\n",
    "            pair = np.zeros((2, num_features))\n",
    "            pair[0] = features_train[train_idx]\n",
    "            pair[1] = features_test[test_idx]\n",
    "            current_K = qk.evaluate(pair)\n",
    "            new_sum = new_sum + alpha[train_idx] * labels_train[train_idx] * current_K[0][1] # x_i vs x (test)\n",
    "\n",
    "        if int(new_sum/abs(new_sum)) == int(labels_test[test_idx]):\n",
    "            good = good + 1\n",
    "        #    print(\"Good for \" + str(test_idx))\n",
    "        else:\n",
    "            bad = bad + 1\n",
    "        #    print(\"Bad for \" + str(test_idx))\n",
    "        \n",
    "        if round(good / (good + bad), 4) * 100 > best_acc:\n",
    "            best_acc = round(good / (good + bad), 4) * 100\n",
    "            lambda_best_acc = lambda_svm\n",
    "    \n",
    "    with open(numerical_results_filename, 'a') as f:\n",
    "        print(\"Lambda is: \", lambda_svm, file=f)\n",
    "        print(\"Well classifed: \", good, file=f)\n",
    "        print(\"Bad classified: \", bad, file=f)\n",
    "        print(\"Accuracy: \", round(good / (good + bad), 4) * 100, file=f)\n",
    "        print('\\n################################\\n', file=f)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b1a474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for best lambda\n",
    "lambda_svm = lambda_best_acc # we plot for the best lambda\n",
    "Q = np.zeros((num_samples_train, num_samples_train))\n",
    "for i in range(num_samples_train):\n",
    "    for j in range(num_samples_train):\n",
    "        Q[i][j] = labels[i] * labels[j] * K[i][j]\n",
    "Pm = np.eye(num_samples_train) / lambda_svm + Q\n",
    "\n",
    "P = matrix(Pm, tc='d')\n",
    "q = matrix(-np.ones(num_samples_train), tc='d')\n",
    "G = matrix(-np.eye(num_samples_train), tc='d')\n",
    "h = matrix(np.zeros(num_samples_train), tc='d')\n",
    "\n",
    "sol = solvers.qp(P,q,G,h)\n",
    "alpha = (np.array(sol['x']).T)[0]\n",
    "print(alpha[0:4])\n",
    "good = 0\n",
    "bad = 0\n",
    "\n",
    "w_0 = 0\n",
    "w_1 = 0\n",
    "w_2 = 0\n",
    "w_3 = 0\n",
    "\n",
    "for test_idx in range(num_samples_test):\n",
    "    new_sum = 0\n",
    "\n",
    "    for train_idx in range(num_samples_train):\n",
    "        pair = np.zeros((2, num_features))\n",
    "        pair[0] = features_train[train_idx]\n",
    "        pair[1] = features_test[test_idx]\n",
    "        current_K = qk.evaluate(pair)\n",
    "        new_sum = new_sum + alpha[train_idx] * labels_train[train_idx] * current_K[0][1] # x_i vs x (test)\n",
    "        w_0 = w_0 + alpha[train_idx] * labels_train[train_idx] * features_train[train_idx][0]\n",
    "        w_1 = w_1 + alpha[train_idx] * labels_train[train_idx] * features_train[train_idx][1]\n",
    "        w_2 = w_2 + alpha[train_idx] * labels_train[train_idx] * features_train[train_idx][2]\n",
    "        w_3 = w_3 + alpha[train_idx] * labels_train[train_idx] * features_train[train_idx][3]\n",
    "\n",
    "##\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for key, group in grouped:\n",
    "    group.plot(ax=ax, kind='scatter', x='feature 1', y='feature 2', label=key, color=colors[key])\n",
    "    \n",
    "x0_sample = np.linspace(-10.0, 10.0, num=1000)\n",
    "x1_sample = -w_0 * x0_sample / w_1\n",
    "ax.plot(x0_sample, x1_sample)\n",
    "\n",
    "plt.savefig(foldername + 'pauli_fm_hyperplane_f1_f2.png')\n",
    "plt.show()\n",
    "\n",
    "##\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for key, group in grouped:\n",
    "    group.plot(ax=ax, kind='scatter', x='feature 2', y='feature 3', label=key, color=colors[key])\n",
    "\n",
    "x0_sample = np.linspace(-10.0, 10.0, num=1000)\n",
    "x1_sample = -w_1 * x0_sample / w_2\n",
    "ax.plot(x0_sample, x1_sample)\n",
    "\n",
    "plt.savefig(foldername + 'pauli_fm_hyperplane_f2_f3.png')\n",
    "plt.show()\n",
    "\n",
    "##\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for key, group in grouped:\n",
    "    group.plot(ax=ax, kind='scatter', x='feature 3', y='feature 4', label=key, color=colors[key])\n",
    "\n",
    "x0_sample = np.linspace(-10.0, 10.0, num=1000)\n",
    "x1_sample = -w_2 * x0_sample / w_3\n",
    "ax.plot(x0_sample, x1_sample)\n",
    "\n",
    "plt.savefig(foldername + 'pauli_fm_hyperplane_f3_f4.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8a194d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
